{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sign Recognizer CNN Data\n",
    "\n",
    "This notebook will create the training data for the sign recognizer CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import text\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 96, 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make smaller images of non signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob, os\n",
    "from sklearn.feature_extraction import image\n",
    "from scipy.ndimage import imread\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/home/nathan/olin/spring2017/sign_follower/scripts/data/room\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 18.40it/s]\u001b[A\n",
      "5it [00:00, 18.08it/s]\u001b[A\n",
      "8it [00:00, 18.33it/s]\u001b[A\n",
      "10it [00:00, 17.37it/s]\u001b[A\n",
      "12it [00:00, 17.66it/s]\u001b[A\n",
      "15it [00:00, 18.82it/s]\u001b[A\n",
      "17it [00:00, 17.28it/s]\u001b[A\n",
      "19it [00:01, 17.99it/s]\u001b[A\n",
      "22it [00:01, 19.54it/s]\u001b[A\n",
      "24it [00:01, 18.77it/s]\u001b[A\n",
      "27it [00:01, 19.61it/s]\u001b[A\n",
      "30it [00:01, 20.38it/s]\u001b[A\n",
      "33it [00:01, 20.17it/s]\u001b[A\n",
      "36it [00:01, 19.22it/s]\u001b[A\n",
      "38it [00:01, 19.35it/s]\u001b[A\n",
      "40it [00:02, 17.83it/s]\u001b[A\n",
      "42it [00:02, 17.02it/s]\u001b[A\n",
      "44it [00:02, 16.78it/s]\u001b[A\n",
      "46it [00:02, 16.38it/s]\u001b[A\n",
      "48it [00:02, 15.76it/s]\u001b[A\n",
      "50it [00:02, 16.50it/s]\u001b[A\n",
      "53it [00:02, 18.02it/s]\u001b[A\n",
      "56it [00:03, 18.61it/s]\u001b[A\n",
      "58it [00:03, 17.96it/s]\u001b[A\n",
      "60it [00:03, 17.34it/s]\u001b[A\n",
      "62it [00:03, 16.12it/s]\u001b[A\n",
      "65it [00:03, 17.17it/s]\u001b[A\n",
      "67it [00:03, 16.40it/s]\u001b[A\n",
      "69it [00:03, 17.07it/s]\u001b[A\n",
      "71it [00:03, 17.42it/s]\u001b[A\n",
      "73it [00:04, 17.11it/s]\u001b[A\n",
      "76it [00:04, 17.68it/s]\u001b[A\n",
      "79it [00:04, 19.65it/s]\u001b[A\n",
      "82it [00:04, 19.38it/s]\u001b[A\n",
      "84it [00:04, 18.74it/s]\u001b[A\n",
      "87it [00:04, 19.27it/s]\u001b[A\n",
      "90it [00:04, 19.00it/s]\u001b[A\n",
      "92it [00:05, 18.25it/s]\u001b[A\n",
      "94it [00:05, 17.12it/s]\u001b[A\n",
      "97it [00:05, 18.26it/s]\u001b[A\n",
      "99it [00:05, 16.43it/s]\u001b[A\n",
      "102it [00:05, 17.60it/s]\u001b[A\n",
      "104it [00:05, 16.90it/s]\u001b[A\n",
      "106it [00:05, 16.42it/s]\u001b[A\n",
      "108it [00:05, 16.38it/s]\u001b[A\n",
      "110it [00:06, 17.09it/s]\u001b[A\n",
      "113it [00:06, 18.96it/s]\u001b[A\n",
      "115it [00:06, 17.89it/s]\u001b[A\n",
      "117it [00:06, 18.03it/s]\u001b[A\n",
      "119it [00:06, 16.86it/s]\u001b[A\n",
      "121it [00:06, 17.28it/s]\u001b[A\n",
      "124it [00:06, 18.23it/s]\u001b[A\n",
      "127it [00:06, 20.59it/s]\u001b[A\n",
      "130it [00:07, 20.40it/s]\u001b[A\n",
      "133it [00:07, 19.53it/s]\u001b[A\n",
      "136it [00:07, 18.38it/s]\u001b[A\n",
      "139it [00:07, 20.30it/s]\u001b[A\n",
      "142it [00:07, 19.73it/s]\u001b[A\n",
      "145it [00:07, 19.47it/s]\u001b[A\n",
      "149it [00:07, 21.06it/s]\u001b[A\n",
      "152it [00:08, 20.73it/s]\u001b[A\n",
      "155it [00:08, 18.45it/s]\u001b[A\n",
      "157it [00:08, 18.32it/s]\u001b[A\n",
      "159it [00:08, 16.95it/s]\u001b[A\n",
      "162it [00:08, 18.84it/s]\u001b[A\n",
      "164it [00:08, 17.19it/s]\u001b[A\n",
      "166it [00:08, 17.11it/s]\u001b[A\n",
      "168it [00:09, 16.97it/s]\u001b[A\n",
      "1233it [01:12, 16.99it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, file in tqdm(enumerate(glob.glob(\"*.png\"))):\n",
    "    img  = Image.open(file)\n",
    "    data = np.asarray(img)\n",
    "    patches = image.extract_patches_2d(data, (img_rows, img_cols), max_patches=20)\n",
    "    for j, patch in enumerate(patches):\n",
    "        img = Image.fromarray(patch, 'RGB')\n",
    "        img.save('../train2/notSign2/notSign_{}_{}.png'.format(i, j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Make small images of signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/home/nathan/olin/spring2017/sign_follower/scripts/data/sign2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imresize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "425it [00:05, 81.54it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, file in tqdm(enumerate(glob.glob(\"*.png\"))):\n",
    "    img  = Image.open(file)\n",
    "    data = np.asarray(img)\n",
    "    img = Image.fromarray(imresize(data, (img_rows, img_cols, 3)))\n",
    "    img.save('../train2/sign2small/sign_{}.png'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python deep learning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
